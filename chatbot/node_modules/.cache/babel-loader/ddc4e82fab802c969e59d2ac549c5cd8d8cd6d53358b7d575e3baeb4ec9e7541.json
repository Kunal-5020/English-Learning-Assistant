{"ast":null,"code":"var _s = $RefreshSig$();\nimport { useState, useEffect, useRef } from 'react';\nconst useVoiceRecognition = () => {\n  _s();\n  const [transcript, setTranscript] = useState('');\n  const recognitionRef = useRef(null);\n  useEffect(() => {\n    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    if (SpeechRecognition) {\n      const recognitionInstance = new SpeechRecognition();\n      recognitionInstance.interimResults = true;\n      recognitionInstance.lang = 'en-US';\n      recognitionInstance.onresult = event => {\n        const currentTranscript = Array.from(event.results).map(result => result[0].transcript).join('');\n        setTranscript(currentTranscript);\n      };\n      recognitionInstance.onerror = event => {\n        console.error('Speech recognition error detected: ' + event.error);\n      };\n      recognitionInstance.onend = () => {\n        setTimeout(() => {\n          recognitionInstance.start();\n        }, 1000);\n      };\n      recognitionRef.current = recognitionInstance;\n    } else {\n      console.error('Speech recognition not supported in this browser.');\n    }\n    return () => {\n      if (recognitionRef.current) {\n        recognitionRef.current.stop();\n      }\n    };\n  }, []);\n  const startListening = () => {\n    if (recognitionRef.current && recognitionRef.current.state !== 'running') {\n      setTranscript('');\n      recognitionRef.current.start();\n    }\n  };\n  const stopListening = () => {\n    if (recognitionRef.current) {\n      recognitionRef.current.stop();\n    }\n  };\n  return {\n    transcript,\n    startListening,\n    stopListening\n  };\n};\n_s(useVoiceRecognition, \"F6Qitv5pvneG7GdTutat1/FNjnw=\");\nexport default useVoiceRecognition;","map":{"version":3,"names":["useState","useEffect","useRef","useVoiceRecognition","_s","transcript","setTranscript","recognitionRef","SpeechRecognition","window","webkitSpeechRecognition","recognitionInstance","interimResults","lang","onresult","event","currentTranscript","Array","from","results","map","result","join","onerror","console","error","onend","setTimeout","start","current","stop","startListening","state","stopListening"],"sources":["C:/Users/kunal/OneDrive/Desktop/office work/Hindi Chat Bot/chatbot/src/voice/voice-to-text.js"],"sourcesContent":["import { useState, useEffect, useRef } from 'react';\r\n\r\nconst useVoiceRecognition = () => {\r\n    const [transcript, setTranscript] = useState('');\r\n    const recognitionRef = useRef(null);\r\n\r\n    useEffect(() => {\r\n        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\r\n        if (SpeechRecognition) {\r\n            const recognitionInstance = new SpeechRecognition();\r\n            recognitionInstance.interimResults = true;\r\n            recognitionInstance.lang = 'en-US';\r\n\r\n            recognitionInstance.onresult = (event) => {\r\n                const currentTranscript = Array.from(event.results)\r\n                    .map(result => result[0].transcript)\r\n                    .join('');\r\n                setTranscript(currentTranscript);\r\n            };\r\n\r\n            recognitionInstance.onerror = (event) => {\r\n                console.error('Speech recognition error detected: ' + event.error);\r\n            };\r\n\r\n            recognitionInstance.onend = () => {\r\n                setTimeout(() => {\r\n                    recognitionInstance.start();\r\n                }, 1000);\r\n            };\r\n\r\n            recognitionRef.current = recognitionInstance;\r\n        } else {\r\n            console.error('Speech recognition not supported in this browser.');\r\n        }\r\n\r\n        return () => {\r\n            if (recognitionRef.current) {\r\n                recognitionRef.current.stop();\r\n            }\r\n        };\r\n    }, []);\r\n\r\n    const startListening = () => {\r\n        if (recognitionRef.current && recognitionRef.current.state !== 'running') {\r\n            setTranscript('');\r\n            recognitionRef.current.start();\r\n        }\r\n    };\r\n\r\n    const stopListening = () => {\r\n        if (recognitionRef.current) {\r\n            recognitionRef.current.stop();\r\n        }\r\n    };\r\n\r\n    return { transcript, startListening, stopListening };\r\n};\r\n\r\nexport default useVoiceRecognition;\r\n"],"mappings":";AAAA,SAASA,QAAQ,EAAEC,SAAS,EAAEC,MAAM,QAAQ,OAAO;AAEnD,MAAMC,mBAAmB,GAAGA,CAAA,KAAM;EAAAC,EAAA;EAC9B,MAAM,CAACC,UAAU,EAAEC,aAAa,CAAC,GAAGN,QAAQ,CAAC,EAAE,CAAC;EAChD,MAAMO,cAAc,GAAGL,MAAM,CAAC,IAAI,CAAC;EAEnCD,SAAS,CAAC,MAAM;IACZ,MAAMO,iBAAiB,GAAGC,MAAM,CAACD,iBAAiB,IAAIC,MAAM,CAACC,uBAAuB;IACpF,IAAIF,iBAAiB,EAAE;MACnB,MAAMG,mBAAmB,GAAG,IAAIH,iBAAiB,CAAC,CAAC;MACnDG,mBAAmB,CAACC,cAAc,GAAG,IAAI;MACzCD,mBAAmB,CAACE,IAAI,GAAG,OAAO;MAElCF,mBAAmB,CAACG,QAAQ,GAAIC,KAAK,IAAK;QACtC,MAAMC,iBAAiB,GAAGC,KAAK,CAACC,IAAI,CAACH,KAAK,CAACI,OAAO,CAAC,CAC9CC,GAAG,CAACC,MAAM,IAAIA,MAAM,CAAC,CAAC,CAAC,CAAChB,UAAU,CAAC,CACnCiB,IAAI,CAAC,EAAE,CAAC;QACbhB,aAAa,CAACU,iBAAiB,CAAC;MACpC,CAAC;MAEDL,mBAAmB,CAACY,OAAO,GAAIR,KAAK,IAAK;QACrCS,OAAO,CAACC,KAAK,CAAC,qCAAqC,GAAGV,KAAK,CAACU,KAAK,CAAC;MACtE,CAAC;MAEDd,mBAAmB,CAACe,KAAK,GAAG,MAAM;QAC9BC,UAAU,CAAC,MAAM;UACbhB,mBAAmB,CAACiB,KAAK,CAAC,CAAC;QAC/B,CAAC,EAAE,IAAI,CAAC;MACZ,CAAC;MAEDrB,cAAc,CAACsB,OAAO,GAAGlB,mBAAmB;IAChD,CAAC,MAAM;MACHa,OAAO,CAACC,KAAK,CAAC,mDAAmD,CAAC;IACtE;IAEA,OAAO,MAAM;MACT,IAAIlB,cAAc,CAACsB,OAAO,EAAE;QACxBtB,cAAc,CAACsB,OAAO,CAACC,IAAI,CAAC,CAAC;MACjC;IACJ,CAAC;EACL,CAAC,EAAE,EAAE,CAAC;EAEN,MAAMC,cAAc,GAAGA,CAAA,KAAM;IACzB,IAAIxB,cAAc,CAACsB,OAAO,IAAItB,cAAc,CAACsB,OAAO,CAACG,KAAK,KAAK,SAAS,EAAE;MACtE1B,aAAa,CAAC,EAAE,CAAC;MACjBC,cAAc,CAACsB,OAAO,CAACD,KAAK,CAAC,CAAC;IAClC;EACJ,CAAC;EAED,MAAMK,aAAa,GAAGA,CAAA,KAAM;IACxB,IAAI1B,cAAc,CAACsB,OAAO,EAAE;MACxBtB,cAAc,CAACsB,OAAO,CAACC,IAAI,CAAC,CAAC;IACjC;EACJ,CAAC;EAED,OAAO;IAAEzB,UAAU;IAAE0B,cAAc;IAAEE;EAAc,CAAC;AACxD,CAAC;AAAC7B,EAAA,CAtDID,mBAAmB;AAwDzB,eAAeA,mBAAmB","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}